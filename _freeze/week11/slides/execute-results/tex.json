{
  "hash": "9a19066dde7df6fd34eb01fc2043ed49",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: ETC3550/ETC5550 Applied forecasting\nauthor: \"Week 11: Dynamic regression models\"\nformat:\n  beamer:\n    aspectratio: 169\n    fontsize: 14pt\n    section-titles: false\n    knitr:\n      opts_chunk:\n        dev: \"cairo_pdf\"\n    pdf-engine: pdflatex\n    fig-width: 7.5\n    fig-height: 3.5\n    include-in-header: ../header.tex\n---\n\n\n\n\n## Regression with ARIMA errors\n\n\\vspace*{0.2cm}\\begin{block}{Regression models}\\vspace*{-0.2cm}\n\\[\n  y_t = \\beta_0 + \\beta_1 x_{1,t} + \\dots + \\beta_k x_{k,t} + \\varepsilon_t,\n\\]\n\\end{block}\\vspace*{-0.3cm}\n\n  * $y_t$ modeled as function of $k$ explanatory variables\n$x_{1,t},\\dots,x_{k,t}$.\n  * In regression, we assume that $\\varepsilon_t$ is WN.\n  * Now we want to allow $\\varepsilon_t$ to be autocorrelated.\n\\vspace*{0.1cm}\n\\pause\n\\begin{alertblock}{Example: ARIMA(1,1,1) errors}\\vspace*{-0.8cm}\n\\begin{align*}\n  y_t &= \\beta_0 + \\beta_1 x_{1,t} + \\dots + \\beta_k x_{k,t} + \\eta_t,\\\\\n      & (1-\\phi_1B)(1-B)\\eta_t = (1+\\theta_1B)\\varepsilon_t,\n\\end{align*}\n\\end{alertblock}\n\\rightline{where $\\varepsilon_t$ is white noise.}\n\n## Estimation\n\nIf we minimize $\\sum \\eta_t^2$ (by using ordinary regression):\n\n  1. Estimated coefficients $\\hat{\\beta}_0,\\dots,\\hat{\\beta}_k$ are no longer optimal as some information ignored;\n  2. Statistical tests associated with the model (e.g., t-tests on the coefficients) are incorrect.\n  3. AIC of fitted models misleading.\n\n\\pause\\vspace*{0.4cm}\n\n * Minimizing $\\sum \\varepsilon_t^2$ avoids these problems.\n * Maximizing likelihood similar to minimizing $\\sum \\varepsilon_t^2$.\n\n## Regression with ARIMA errors\n\\fontsize{14}{15}\\sf\n\nAny regression with an ARIMA error can be rewritten as a regression with an ARMA error by differencing all variables.\\pause\n\n\\begin{block}{Original data}\\vspace*{-0.8cm}\n\\begin{align*}\n  y_t & = \\beta_0 + \\beta_1 x_{1,t} + \\dots + \\beta_k x_{k,t} + \\eta_t\\\\\n  \\mbox{where}\\quad\n      & \\phi(B)(1-B)^d\\eta_t = \\theta(B)\\varepsilon_t\n\\end{align*}\n\\end{block}\\pause\\vspace*{-0.1cm}\n\\begin{block}{After differencing all variables}\\vspace*{-0.2cm}\n$$\n  y'_t  = \\beta_1 x'_{1,t} + \\dots + \\beta_k x'_{k,t} + \\eta'_t.\n$$\nwhere $\\phi(B)\\eta'_t = \\theta(B)\\varepsilon_t$,\\vspace*{0.1cm}\n\n$y_t' = (1-B)^dy_t$,\\quad $x_{i,t}' = (1-B)^dx_{i,t}$,\\quad and $\\eta_t' = (1-B)^d \\eta_t$\n\\end{block}\n\n## Regression with ARIMA errors\n\n  * In R, we can specify an ARIMA($p,d,q$) for the errors, and $d$ levels of differencing will be applied to all variables ($y, x_{1,t},\\dots,x_{k,t}$) during estimation.\n  * Check that $\\varepsilon_t$ series looks like white noise.\n  * AICc can be calculated for final model.\n  * Repeat procedure for all subsets of predictors to be considered, and select model with lowest AICc value.\n\n## Forecasting\n\n  * To forecast a regression model with ARIMA errors, we need to forecast the\nregression part of the model and the ARIMA part of the model and combine the\nresults.\n  * Some predictors are known into the future (e.g., time, dummies).\n  * Separate forecasting models may be needed for other predictors.\n  * Forecast intervals ignore the uncertainty in forecasting the predictors.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}