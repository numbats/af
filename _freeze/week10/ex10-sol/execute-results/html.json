{
  "hash": "1a9fa2e365354bd6441765366618b71a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercise Week 10: Solutions\"\n---\n\n\n\n# fpp3 9.11, Ex11\n\n> Choose one of the following seasonal time series: the Australian production of electricity, cement, or gas (from `aus_production`).\n>\n>   a. Do the data need transforming? If so, find a suitable transformation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_production |>\n  autoplot(Electricity)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11a-1.png){width=672}\n:::\n:::\n\n\nYes, these need transforming.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda <- aus_production |>\n  features(Electricity, guerrero) |>\n  pull(lambda_guerrero)\naus_production |>\n  autoplot(box_cox(Electricity, lambda))\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11a2-1.png){width=672}\n:::\n:::\n\n\n`guerrero()` suggests using Box-Cox transformation with parameter $\\lambda=0.52$.\n\n>   b. Are the data stationary? If not, find an appropriate differencing which yields stationary data.\n\nThe trend and seasonality show that the data are not stationary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_production |>\n  gg_tsdisplay(box_cox(Electricity, lambda) |> difference(4), plot_type = \"partial\")\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11b-1.png){width=672}\n:::\n\n```{.r .cell-code}\naus_production |>\n  gg_tsdisplay(box_cox(Electricity, lambda) |> difference(4) |> difference(1), plot_type = \"partial\")\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11b-2.png){width=672}\n:::\n:::\n\n\nIt seems that we could have continued with only taking seasonal differences. You may try this option. We opt to take a first order difference as well.\n\n>   c. Identify a couple of ARIMA models that might be useful in describing the time series. Which of your models is the best according to their AIC values?\n\nFrom the above graph, an AR(1) or an MA(1) with a seasonal MA(2) might work. So an ARIMA(1,1,0)(0,1,2) model for the transformed data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- aus_production |>\n  model(\n    manual = ARIMA(box_cox(Electricity, lambda) ~ 0 + pdq(1, 1, 0) + PDQ(0, 1, 2)),\n    auto = ARIMA(box_cox(Electricity, lambda))\n  )\nfit |>\n  select(auto) |>\n  report()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Electricity \nModel: ARIMA(1,1,4)(0,1,1)[4] \nTransformation: box_cox(Electricity, lambda) \n\nCoefficients:\n          ar1     ma1      ma2      ma3      ma4     sma1\n      -0.7030  0.2430  -0.4477  -0.1553  -0.2452  -0.5574\ns.e.   0.1739  0.1943   0.0973   0.0931   0.1189   0.1087\n\nsigma^2 estimated as 18.02:  log likelihood=-609.08\nAIC=1232.17   AICc=1232.71   BIC=1255.7\n```\n\n\n:::\n\n```{.r .cell-code}\nglance(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n  .model sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots \n  <chr>   <dbl>   <dbl> <dbl> <dbl> <dbl> <list>    <list>   \n1 manual   19.7   -620. 1247. 1248. 1261. <cpl [1]> <cpl [8]>\n2 auto     18.0   -609. 1232. 1233. 1256. <cpl [1]> <cpl [8]>\n```\n\n\n:::\n:::\n\n\nAutomatic model selection with `ARIMA()` has also taken a first order difference, and so we can compare the AICc values. This is a challenging ARIMA model to select manually and the automatic model is clearly better.\n\n>   d. Estimate the parameters of your best model and do diagnostic testing on the residuals. Do the residuals resemble white noise? If not, try to find another ARIMA model which fits better.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(auto) |>\n  gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11d-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit |>\n  select(auto) |>\n  augment() |>\n  features(.innov, ljung_box, dof = 6, lag = 12)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 auto      8.45     0.207\n```\n\n\n:::\n:::\n\n\nResiduals look reasonable, they resemble white noise.\n\n>   e. Forecast the next 24 months of data using your preferred model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(auto) |>\n  forecast(h = \"2 years\") |>\n  autoplot(aus_production)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11e-1.png){width=672}\n:::\n:::\n\n\n>   f. Compare the forecasts obtained using `ETS()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_production |>\n  model(ETS(Electricity)) |>\n  forecast(h = \"2 years\") |>\n  autoplot(aus_production)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11f-1.png){width=672}\n:::\n\n```{.r .cell-code}\naus_production |>\n  model(ETS(Electricity)) |>\n  forecast(h = \"2 years\") |>\n  autoplot(aus_production |> filter(year(Quarter) >= 2000)) +\n  autolayer(fit |> select(auto) |> forecast(h = \"2 years\"), colour = \"red\", alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex11f-2.png){width=672}\n:::\n:::\n\n\nThe point forecasts appear to be quite similar. The ETS forecasts have a wider forecast interval than the ARIMA forecasts.\n\n# fpp3 9.11, Ex12\n\n> For the same time series you used in the previous exercise, try using a non-seasonal model applied to the seasonally adjusted data obtained from STL. Compare the forecasts with those obtained in the previous exercise. Which do you think is the best approach?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda <- aus_production |>\n  features(Electricity, guerrero) |>\n  pull(lambda_guerrero)\nstlarima <- decomposition_model(\n  STL(box_cox(Electricity, lambda)),\n  ARIMA(season_adjust)\n)\nfc <- aus_production |>\n  model(\n    ets = ETS(Electricity),\n    arima = ARIMA(box_cox(Electricity, lambda)),\n    stlarima = stlarima\n  ) |>\n  forecast(h = \"2 years\")\nfc |> autoplot(aus_production |> filter(year(Quarter) > 2000), level=95)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex12-1.png){width=672}\n:::\n:::\n\n\nThe STL-ARIMA approach has higher values and narrower prediction intervals. It is hard to know which is best without comparing against a test set.\n\n\n# fpp3 9.11, Ex13\n\n> For the Australian tourism data (from `tourism`):\n>   a. Fit a suitable ARIMA model for all data.\n>   b. Produce forecasts of your fitted models.\n>   c. Check the forecasts for the \"Snowy Mountains\" and \"Melbourne\" regions. Do they look reasonable?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- tourism |>\n  model(arima = ARIMA(Trips))\nfc <- fit |> forecast(h=\"3 years\")\nfc |>\n  filter(Region == \"Snowy Mountains\") |>\n  autoplot(tourism)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfc |>\n  filter(Region == \"Melbourne\") |>\n  autoplot(tourism)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex13-2.png){width=672}\n:::\n:::\n\n\nBoth sets of forecasts appear to have captured the underlying trend and seasonality effectively.\n\n# fpp3 9.11, Ex14\n\n> For your retail time series (Exercise 5):\n>    a. develop an appropriate seasonal ARIMA model;\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345678)\nmyseries <- aus_retail |>\n  filter(\n    `Series ID` == sample(aus_retail$`Series ID`, 1),\n    Month < yearmonth(\"2018 Jan\")\n  )\nfit <- myseries |>\n  model(arima = ARIMA(log(Turnover)))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Turnover \nModel: ARIMA(1,0,2)(1,1,1)[12] w/ drift \nTransformation: log(Turnover) \n\nCoefficients:\n         ar1      ma1     ma2    sar1     sma1  constant\n      0.9635  -0.3968  0.0538  0.1518  -0.8869    0.0016\ns.e.  0.0190   0.0574  0.0555  0.0807   0.0643    0.0003\n\nsigma^2 estimated as 0.004626:  log likelihood=432.96\nAIC=-851.91   AICc=-851.58   BIC=-825.01\n```\n\n\n:::\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/ex14a-1.png){width=672}\n:::\n:::\n\n\n>    b. compare the forecasts with those you obtained in earlier chapters;\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstlets <- decomposition_model(\n  STL(log(Turnover)),\n  ETS(season_adjust)\n)\nstlarima <- decomposition_model(\n  STL(log(Turnover)),\n  ARIMA(season_adjust)\n)\nfit <- myseries |>\n  model(\n    ets = ETS(Turnover),\n    arima = ARIMA(log(Turnover)),\n    stlets = stlets,\n    stlarima = stlarima\n  )\nfc <- fit |>\n  forecast(h=\"3 years\")\nfc |>\n  accuracy(aus_retail) |>\n  select(.model, RMSE, MAE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  .model    RMSE   MAE\n  <chr>    <dbl> <dbl>\n1 arima    1.41  1.14 \n2 ets      0.967 0.777\n3 stlarima 0.641 0.487\n4 stlets   1.14  0.838\n```\n\n\n:::\n:::\n\n\nFrom these 4 models, the STL-ARIMA model is doing better than the others.\n\n>    c. Obtain up-to-date retail data from the [ABS website](https://bit.ly/absretail) (Cat 8501.0, Table 11), and compare your forecasts with the actual numbers. How good were the forecasts from the various models?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nupdate <- readabs::read_abs(series_id = myseries$`Series ID`[1],\n                            release_date = \"2022-12-31\") |>\n  mutate(\n    Month = yearmonth(date),\n    Turnover = value\n  ) |>\n  select(Month, Turnover) |>\n  filter(Month > max(myseries$Month)) |>\n  as_tsibble(index=Month)\nfc |>\n  accuracy(update)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  .model   .type     ME  RMSE   MAE     MPE  MAPE  MASE RMSSE  ACF1\n  <chr>    <chr>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl>\n1 arima    Test  -2.68   3.28  2.68 -22.9   22.9    NaN   NaN 0.700\n2 ets      Test  -1.42   2.17  1.60 -13.5   14.3    NaN   NaN 0.564\n3 stlarima Test   0.379  1.81  1.12  -0.369  9.23   NaN   NaN 0.541\n4 stlets   Test  -1.89   2.59  1.95 -16.8   17.2    NaN   NaN 0.623\n```\n\n\n:::\n:::\n\n\nWith a longer test set, the STL-ARIMA model is still best.\n\n# fpp3 9.11, Ex15\n\n> Consider the number of Snowshoe Hare furs traded by the Hudson Bay Company between 1845 and 1935 (data set `pelt`).\n>\n>    a. Produce a time plot of the time series.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npelt |>\n  autoplot(Hare)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n>    b. Assume you decide to fit the following model:\n> $$ y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\phi_3 y_{t-3} + \\phi_4 y_{t-4} + \\varepsilon_t, $$\n>        where $\\varepsilon_t$ is a white noise series. What sort of ARIMA model is this (i.e., what are $p$, $d$, and $q$)?\n\n- This is an ARIMA(4,0,0), hence $p=4$, $d=0$ and $q=0$.\n\n>    c. By examining the ACF and PACF of the data, explain why this model is appropriate.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npelt |> gg_tsdisplay(Hare, plot=\"partial\")\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit <- pelt |> model(AR4 = ARIMA(Hare ~ pdq(4,0,0)))\nfit |> gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n- The significant spike at lag 4 of the PACF indicates an AR(4).\n- The residuals from this model are clearly whhite noise.\n\n>    d. The last five values of the series are given below:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Year                 |  1931|  1932|  1933|  1934|  1935|\n|:--------------------|-----:|-----:|-----:|-----:|-----:|\n|Number of hare pelts | 19520| 82110| 89760| 81660| 15760|\n\n\n:::\n:::\n\n\n>   The estimated parameters are\n>    $c = 30993$,\n>    $\\phi_1 = 0.82194$,\n>    $\\phi_2 = -0.28906$,\n>    $\\phi_3 = -0.00570$, and\n>    $\\phi_4 = -0.21652$.\n>    Without using the `forecast` function, calculate forecasts for the next three years (1936--1939).\n\n\\begin{align*}\n  \\hat{y}_{T+1|T} & = 30993 +\n    0.82194* 15760\n    -0.28906* 81660\n    -0.00570* 89760\n    -0.21652* 82110 =\n    2051.57 \\\\\n  \\hat{y}_{T+2|T} & = 30993 +\n    0.82194* 2051.57\n    -0.28906* 15760\n    -0.00570* 81660\n    -0.21652* 89760 =\n    8223.14 \\\\\n  \\hat{y}_{T+3|T} & = 30993 +\n    0.82194* 8223.14\n    -0.28906* 2051.57\n    -0.00570* 15760\n    -0.21652* 81660 =\n    19387.96\n\\end{align*}\n\n>    e. Now fit the model in R and obtain the forecasts using `forecast`. How are they different from yours? Why?\n\n\n::: {.cell}\n\n```{.r .cell-code}\npelt |>\n  model(ARIMA(Hare ~ pdq(4, 0, 0))) |>\n  forecast(h=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 3 x 4 [1Y]\n# Key:     .model [1]\n  .model     Year              Hare  .mean\n  <chr>     <dbl>            <dist>  <dbl>\n1 ARIMA(Ha…  1936  N(2052, 5.9e+08)  2052.\n2 ARIMA(Ha…  1937  N(8223, 9.8e+08)  8223.\n3 ARIMA(Ha…  1938 N(19388, 1.1e+09) 19388.\n```\n\n\n:::\n:::\n\n\nAny differences will be due to rounding errors.\n\n# fpp3 9.11, Ex16\n\n> The population of Switzerland from 1960 to 2017 is in data set `global_economy`.\n\n>    a. Produce a time plot of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswiss_pop <- global_economy |>\n  filter(Country == \"Switzerland\") |>\n  select(Year, Population) |>\n  mutate(Population = Population / 1e6)\n\nautoplot(swiss_pop, Population)\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n>    b. You decide to fit the following model to the series:\n>$$y_t = c + y_{t-1} + \\phi_1 (y_{t-1} - y_{t-2}) + \\phi_2 (y_{t-2} - y_{t-3}) + \\phi_3( y_{t-3} - y_{t-4}) + \\varepsilon_t$$\n> where $y_t$ is the Population in year $t$ and $\\varepsilon_t$ is a white noise series. What sort of ARIMA model is this (i.e., what are $p$, $d$, and $q$)?\n\nThis is an ARIMA(3,1,0), hence $p=3$, $d=1$ and $q=0$.\n\n>    c. Explain why this model was chosen using the ACF and PACF of the differenced series.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswiss_pop |> gg_tsdisplay(Population, plot=\"partial\")\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswiss_pop |> gg_tsdisplay(difference(Population), plot=\"partial\")\n```\n\n::: {.cell-output-display}\n![](ex10-sol_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe significant spike at lag 3 in the PACF, coupled with the  exponential decay in the ACF, for the differenced series, signals an AR(3) for the differenced series.\n\n>    d. The last five values of the series are given below.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Year                  | 2013| 2014| 2015| 2016| 2017|\n|:---------------------|----:|----:|----:|----:|----:|\n|Population (millions) | 8.09| 8.19| 8.28| 8.37| 8.47|\n\n\n:::\n:::\n\n\n> The estimated parameters are $c = 0.0053$, $\\phi_1 = 1.64$, $\\phi_2 = -1.17$, and $\\phi_3 = 0.45$. Without using the `forecast` function, calculate forecasts for the next three years (2018--2020).\n\n\\begin{align*}\n  \\hat{y}_{T+1|T} & = 0.0053 +\n  8.47+\n    1.64* (8.47 - 8.37)\n    -1.17* (8.37 - 8.28) +\n    0.45* (8.28 - 8.19) =\n    8.56 \\\\\n  \\hat{y}_{T+2|T} & = 0.0053 +\n  8.56+\n    1.64* (8.56 - 8.47)\n    -1.17* (8.47 - 8.37) +\n    0.45* (8.37 - 8.28) =\n    8.65 \\\\\n  \\hat{y}_{T+3|T} & = 0.0053 +\n  8.65+\n    1.64* (8.65 - 8.56)\n    -1.17* (8.56 - 8.47) +\n    0.45* (8.47 - 8.37) =\n    8.73 \\\\\n\\end{align*}\n\n>   e. Now fit the model in R and obtain the forecasts from the same model. How are they different from yours? Why?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Country == \"Switzerland\") |>\n  mutate(Population = Population / 1e6) |>\n  model(ARIMA(Population ~ 1 + pdq(3, 1, 0))) |>\n  forecast(h=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 3 x 5 [1Y]\n# Key:     Country, .model [1]\n  Country   .model  Year      Population\n  <fct>     <chr>  <dbl>          <dist>\n1 Switzerl… ARIMA…  2018 N(8.6, 0.00013)\n2 Switzerl… ARIMA…  2019   N(8.6, 0.001)\n3 Switzerl… ARIMA…  2020  N(8.7, 0.0033)\n# ℹ 1 more variable: .mean <dbl>\n```\n\n\n:::\n:::\n\n\nAny differences will be due to rounding errors.\n",
    "supporting": [
      "ex10-sol_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}